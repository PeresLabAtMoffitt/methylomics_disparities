---
title: "Bayesian Consensus Clustering"
author: "Christelle Colin-Leitzinger"
date: '`r Sys.Date()`'
output: 
  html_document:
    toc: true
    toc_float: true
    toc_collapsed: false
    theme: united
    code_folding: hide
    highlight: pygments
    df_print: paged
editor_options: 
  chunk_output_type: console
---

<style type="text/css">

.figure {
   margin-top: 25px;
   margin-bottom: 100px;
}

table {
    margin-top: 10px;
    margin-bottom: 25px;
}
</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(
                      warning = FALSE,
                      message = FALSE,
                      cache = FALSE,
                      fig.align='center'
                      )
```

```{r library, echo = FALSE}
library(tidyverse)
library(REMP)
library(LaplacesDemon)
library(ComplexHeatmap)
library(ggridges)

theme_gtsummary_compact()
theme_set(theme_classic())
```
ConsensusClusterPlus Paper:  
https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2881355/

Algorithm
ConsensusClusterPlus extends the CC algorithm and is briefly described here. The algorithm begins by subsampling a proportion of items and a proportion of features from a data matrix. Each subsample is then partitioned into up to k groups by a user-specified clustering algorithm: agglomerative hierarchical clustering, k-means or a custom algorithm. This process is repeated for a specified number of repetitions. Pairwise consensus values, defined as ‘the proportion of clustering runs in which two items are [grouped] together’ (Monti et al., 2003), are calculated and stored in a consensus matrix (CM) for each k. Then for each k, a final agglomerative hierarchical consensus clustering using distance of 1−consensus values is completed and pruned to k groups, which are called consensus clusters.

```{r load data}
remp_res_Alu <- read_rds(paste0(here::here(), "/intermediary data/remp_results_Alu.rds"))
annot_res_Alu <- read_rds(paste0(here::here(), "/intermediary data/remp_res_Alu_annotation.rds"))
remp_res_ERV <- read_rds(paste0(here::here(), "/intermediary data/remp_results_ERV.rds"))
annot_res_ERV <- read_rds(paste0(here::here(), "/intermediary data/remp_res_ERV_annotation.rds"))
remp_res_L1 <- read_rds(paste0(here::here(), "/intermediary data/remp_results_L1.rds"))
annot_res_L1 <- read_rds(paste0(here::here(), "/intermediary data/remp_res_L1_annotation.rds"))
remove_id <- 
  read_csv(paste0(
    here::here(), 
    "/patient_id to remove bc less reliable CpG in expression data after trimming.csv"))
```

# Prep data
Prep each RE type data (coomented code only for L1)
```{r prep individual data, class.source = 'fold-show'}
# Use the non trimmed data to create cluster because need to not have any NAs
# Aggregation step is then done manually to eliminate RE repeat

# L1
# Get Beta
L1_beta_results <- rempB(remp_res_L1)
L1_beta_results <- L1_beta_results %>% as_tibble()  %>%
  cbind(Index = remp_res_L1@rowRanges@elementMetadata$RE.Index, .) %>%
  # remove patient with less reliable CpG data
  select(-remove_id$patient_id) %>%
  # keep only RE that are stable after aggregation and annotation to build the cluster
  filter(str_detect(
    Index, 
    paste0(annot_res_L1@rowRanges@elementMetadata$RE.Index, collapse = "|")))

# patient_id <- colnames(L1_beta_results)[2:ncol(L1_beta_results)]

# Summarize to remove duplicate measurement
L1_df <- L1_beta_results %>%
  group_by(Index) %>%
  mutate(n = n(), .before = 2) %>%
  # Summarize RE when at least 2 predicted CpG sites
  # As rempAggregate() use the mean
  filter(n > 1) %>% select(-n) %>%
  summarise(across(everything(), mean))

L1_df1 <- L1_df %>%
  column_to_rownames("Index") %>% 
  t() %>% 
  scale() %>% t()
```
Do the same for Alu and LTR
```{r}
# Alu
Alu_beta_results <- rempB(remp_res_Alu)
Alu_beta_results <- Alu_beta_results %>% as_tibble() %>%
  cbind(Index = remp_res_Alu@rowRanges@elementMetadata$RE.Index, .) %>%
  select(-remove_id$patient_id) %>% 
  filter(str_detect(
    Index, 
    paste0(annot_res_Alu@rowRanges@elementMetadata$RE.Index, collapse = "|")))

Alu_df <- Alu_beta_results %>%
  group_by(Index) %>%
  mutate(n = n(), .before = 2) %>%
  filter(n > 1) %>% select(-n) %>%
  summarise(across(everything(), mean))

Alu_df1 <- Alu_df %>%
  column_to_rownames("Index") %>% 
  t() %>% 
  scale() %>% t()

# ERV
ERV_beta_results <- rempB(remp_res_ERV)
ERV_beta_results <- ERV_beta_results %>% as_tibble() %>%
  cbind(Index = remp_res_ERV@rowRanges@elementMetadata$RE.Index, .) %>% 
  select(-remove_id$patient_id) %>% 
  filter(str_detect(
    Index, 
    paste0(annot_res_ERV@rowRanges@elementMetadata$RE.Index, collapse = "|")))

ERV_df <- ERV_beta_results %>% 
  group_by(Index) %>% 
  mutate(n = n(), .before = 2) %>% 
  filter(n > 1) %>% select(-n) %>% 
  summarise(across(everything(), mean))

ERV_df1 <- ERV_df %>% 
  column_to_rownames("Index") %>% 
  t() %>% 
  scale() %>% t()
  
```

Start with Bayesian Consensus Clustering with BCC downloaded code (no way of installing the package).  
`r emo::ji("warning")` It doesn't give any help to choose the best k number of cluster!?  
I scaled the data using the scale() function before clustering. I didn't set it up to be from -1 to 1... Should I?
```{r run BCC}
# source(paste0(here::here(), '/R/BCC.r'))

# bcc_res_4 <- BCC(X= list(Alu_df1, ERV_df1, L1_df1),
#     K= 4) # takes about 2h for 4k
write_rds(bcc_res_4, "bcc_scaled_res4k_05172023.rds")
# rm(AlignClusters, BCC, logSum)
bcc_res_4 <- read_rds(paste0(here::here(), "/bcc_scaled_res4k_05172023.rds"))

# bcc_res_4$Alpha
# bcc_res_4$AlphaBounds
# bcc_res_4$Cbest
# # Extract in which cluster [,1] [,2] [,3] ... the patient belong == 1 for each data [[1]] [[2]] [[3]] ...
# bcc_res_4$Lbest
# bcc_res_4$Lbest[[1]] # for the Alu_df1 data
# bcc_res_4$Lbest[[2]][201,] # for variable 201 in ERV data
# bcc_res_4$Lbest[[3]] # for the L1_df1 data
# bcc_res_4$AlphaVec[1000] # 1000 is the last value / is the NumDraws
```

```{r create cluster var}
alu_bcc <- bcc_res_4$Lbest[[1]] %>% 
  as_tibble() %>% 
  # cbind(patient_id = patient_id, .) %>% 
  mutate(bcc_alu = case_when(
    V1 == 1        ~ "1",
    V2 == 1        ~ "2",
    V3 == 1        ~ "3",
    V4 == 1        ~ "4"
  ))
  
erv_bcc <- bcc_res_4$Lbest[[2]] %>% 
  as_tibble() %>% 
  # cbind(patient_id = patient_id, .) %>% 
  mutate(bcc_erv = case_when(
    V1 == 1        ~ "1",
    V2 == 1        ~ "2",
    V3 == 1        ~ "3",
    V4 == 1        ~ "4"
  ))
l1_bcc <- bcc_res_4$Lbest[[3]] %>% 
  as_tibble() %>% 
  # cbind(patient_id = patient_id, .) %>% 
  mutate(bcc_l1 = case_when(
    V1 == 1        ~ "1",
    V2 == 1        ~ "2",
    V3 == 1        ~ "3",
    V4 == 1        ~ "4"
  ))

bayesclus <- bind_cols(patient_id = colnames(ERV_df1),
                       alu_bcc %>% select(bcc_alu),
                       erv_bcc %>% select(bcc_erv),
                       l1_bcc %>% select(bcc_l1))

```


```{r load clean RE}
load(paste0(here::here(), "/cleaned_07082022.rda"))

annot_Alu_beta_results <- rempB(annot_res_Alu)
annot_Alu_beta_results <- annot_Alu_beta_results %>% as_tibble() %>%
  cbind(Index = annot_res_Alu@rowRanges@elementMetadata$RE.Index, .) %>%
  column_to_rownames("Index")
annot_Alu_beta_results1 <- annot_Alu_beta_results %>%
  t() %>% 
  as_tibble(rownames = "patient_id")

annot_L1_beta_results <- rempB(annot_res_L1)
annot_L1_beta_results <- annot_L1_beta_results %>% as_tibble() %>%
  cbind(Index = annot_res_L1@rowRanges@elementMetadata$RE.Index, .) %>%
  column_to_rownames("Index")
annot_L1_beta_results1 <- annot_L1_beta_results %>%
  t() %>% 
  as_tibble(rownames = "patient_id")

annot_ERV_beta_results <- rempB(annot_res_ERV)
annot_ERV_beta_results <- annot_ERV_beta_results %>% as_tibble() %>%
  cbind(Index = annot_res_ERV@rowRanges@elementMetadata$RE.Index, .) %>%
  column_to_rownames("Index")
annot_ERV_beta_results1 <- annot_ERV_beta_results %>%
  t() %>% 
  as_tibble(rownames = "patient_id")
```


```{r merge annotated data with BCC cluster}
beta_clusters <- 
  full_join(bayesclus, annot_Alu_beta_results1,
            by= "patient_id") %>% 
  full_join(., annot_L1_beta_results1,
            by= "patient_id") %>% 
  full_join(., annot_ERV_beta_results1,
            by= "patient_id")
```

# Heatmap BCC
```{r}
map_Alu <- beta_clusters %>%
  select(patient_id, #cluster_Alu, cluster_ERV, cluster_L1, 
         starts_with("Alu_")
         ) %>% 
  # remove patient with less reliable CpG data
  filter(!str_detect(patient_id, remove_id$patient_id)) %>%
  # unite(patient_id, c(patient_id, cluster_L1, cluster_Alu, cluster_ERV), sep = "; c") %>%
  # select(-c(cluster_Alu, cluster_ERV)) %>% 
  column_to_rownames("patient_id")
df_Alu <- t(scale((as.matrix(map_Alu))))[1:100,] # scale for standardizing the data to make variables comparable

column_ho = HeatmapAnnotation(cluster_Alu = c(bayesclus$bcc_alu),
                              cluster_L1 = c(bayesclus$bcc_l1),
                              cluster_ERV = c(bayesclus$bcc_erv),
                              
                              col = list(cluster_Alu = c("1" = "#932667FF", "2" = "grey",
                                                         "3" = "#21908CFF", "4"= "#FDE725FF"),
                                         cluster_L1 = c("1" = "#932667FF", "2" = "grey",
                                                         "3" = "#21908CFF", "4"= "#FDE725FF"),
                                         cluster_ERV = c("1" = "#932667FF", "2" = "grey",
                                                         "3" = "#21908CFF", "4"= "#FDE725FF")
                                         ),
    na_col = "black")
Heatmap(df_Alu, name = "Alu RE hypermethylation",
        na_col = "black",
        show_column_names = FALSE,
        show_row_names = FALSE,
        column_title = "patients",
        column_title_side = "bottom",
        # cluster_rows = FALSE,
        # cluster_columns = FALSE,
        top_annotation = column_ho
        )

beta_clusters %>%
  # select(patient_id, bcc_alu,bcc_erv, bcc_l1,
  #        starts_with("Alu_")
  #        ) %>%
  # remove patient with less reliable CpG data
  filter(!str_detect(patient_id, remove_id$patient_id)) %>%
  pivot_longer(cols = -c(patient_id, bcc_alu, bcc_erv, bcc_l1),
               names_to = "Index", 
               values_to = "RE_value") %>% 
  pivot_longer(cols = c(starts_with("bcc")),
               names_to = "bcc_cluster", 
               values_to = "cluster_value") %>% 
  mutate(RE_type = str_extract(Index, "Alu|L1|ERV")) %>% 
  ggplot(aes(x=RE_value, y=RE_type, fill=cluster_value)) +
  geom_density_ridges(alpha=0.5)+
  theme_ridges()+
  facet_wrap(.~ bcc_cluster)
```



# Clustering using MOVICS
```{r MOVICS}
# devtools::install_github("xlucpu/MOVICS")
# Need to manually add the code of package heatmap.plus in the Library
# Have also other dependencies that needs to be installed by themselves like
# devtools::install_github("maxconway/SNFtool")
# devtools::install_github("danro9685/CIMLR", ref = 'R')
# library("MOVICS")
```

get elites by reducing data dimension.  
Although all these omics data have been already processed (filtered from the original dataset), I am still pleased to show you how to use getElites() function to filter out features that meet some stringent requirements, and those features that are preserved in this procedure are considered elites by MOVICS. Five filtering methods are provided here, namely mad for median absolute deviation, sd for standard deviation, pca for principal components analysis, cox for univariate Cox proportional hazards regression, and freq for binary omics data. This function also handles missing values coded in NA
 by removing them directly or imputing them by k
 nearest neighbors using a Euclidean metric through argument of na.action. Let me show you how to use getElites() below:
```{r get elites}
# Alu_df1, ERV_df1, L1_df1
# tmp <- Alu_df1
# 
# dim(tmp)
# elite.tmp <- getElites(dat       = tmp,
#                        method    = "mad",
#                        na.action = "rm", # NA values will be removed
#                        elite.pct = 1) # elite.pct equals to 1 means all (100%) features after NA removal will be selected even using mad method
# #> --2 features with NA values are removed.
# #> missing elite.num then use elite.pct
# dim(elite.tmp$elite.dat)
```


```{r}
# create list of data




```











